# Datathon â€“ Pipeline CI/CD com Apache Airflow

Este projeto configura um ambiente Apache Airflow utilizando Docker Compose para orquestraÃ§Ã£o de um pipeline de ingestÃ£o, processamento e deploy de modelo preditivo.
ğŸ“ Estrutura do Projeto
```bash 
docker-composer/
â”‚
â”œâ”€â”€ docker-compose.yaml      # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ .env                     # VariÃ¡veis de ambiente
â”œâ”€â”€ dags/                    # DAGs do Airflow
â”‚   â””â”€â”€ dag_cicd_deploy_modelo.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ airflow.cfg          # ConfiguraÃ§Ã£o do Airflow
â”œâ”€â”€ logs/                    # Logs das execuÃ§Ãµes
â””â”€â”€ plugins/                 # Plugins customizados (se houver)

```
### ğŸ§° PrÃ©-requisitos
Antes de iniciar, vocÃª precisa ter instalado:

- âœ… Docker
- âœ… Docker Compose (v2+ recomendado)
- âœ… PermissÃ£o sudo (Linux/Mac)

Verifique:
```bash
docker --version
docker compose version
```

### âš™ï¸ ConfiguraÃ§Ã£o Inicial
#### 1ï¸âƒ£ Acessar a pasta do projeto
```bash
cd docker-composer
```

#### 2ï¸âƒ£ Ajustar permissÃµes (Linux/Mac)
NecessÃ¡rio para evitar erros de permissÃ£o nos volumes do Airflow:
```bash 
sudo chmod -R 777 ./config
sudo chmod -R 777 ./logs
sudo chmod -R 777 ./dags
echo -e "AIRFLOW_UID=$(id -u)" > .env
```

#### 3ï¸âƒ£ Fazer deploy da api modelo
Execute esse comando na raiz do projeto que vocÃª fez o download do git:
```bash 
docker build -t api-datathon:v2.0.0 . 
```

Validar se o nome e a versÃ£o da imagem estÃ£o certo no `docker-compose.yaml`
```
  api-datathon:
    image: api-datathon:v2.0.0
    container_name: api-datathon
```

#### 4ï¸âƒ£ Inicializar o banco do Airflow
Esse comando cria as tabelas internas:
```bash 
docker compose up airflow-init
```

#### â–¶ï¸ Subindo o Ambiente
ApÃ³s a inicializaÃ§Ã£o:
```bash 
docker compose up -d
```

Para verificar os containers:
```bash 
docker ps
````

### ğŸŒ Acessando o Airflow
ApÃ³s subir os containers, acesse:
```browser
http://localhost:8080/
```

ğŸ” Credenciais padrÃ£o:
UsuÃ¡rio: airflow
Senha: airflow

#### ğŸ“Š DAG Principal
A DAG principal estÃ¡ em:

```bash
dags/dag_cicd_deploy_modelo.py
```

Ela executa:
- IngestÃ£o RAW
- IngestÃ£o TRUSTED
- IngestÃ£o REFINED
- Deploy do Modelo
- AvaliaÃ§Ã£o/Teeste do Modelo

### ğŸ§ª Comandos Ãšteis
#### Listar configuraÃ§Ãµes do Airflow
```bash
docker compose run airflow-cli airflow config list
```

#### Ver logs do container da API (caso exista)
```bash
docker logs api-datathon -f
```

#### Ver logs do Airflow
```bash
docker compose logs -f
````

#### Reiniciar ambiente
```bash 
docker compose down
docker compose up -d
```

#### Parar o ambiente
```bash
docker compose down
```

#### Remover containers + volumes (reset completo)
âš ï¸ Isso apaga banco e histÃ³rico de execuÃ§Ãµes
``` bash 
docker compose down --volumes --remove-orphans
```

### ğŸ” Executar DAG Manualmente

1. Acesse o Airflow
2. Ative a DAG
3. Clique em Trigger DAG


### ğŸ“‚ Logs das ExecuÃ§Ãµes
Os logs ficam armazenados em:
```bash
logs/dag_id=dag_cicd_deploy_modelo/
```

### ğŸ›  Desenvolvimento
Sempre que alterar a DAG:

1. Salve o arquivo em dags/
2. O Airflow detectarÃ¡ automaticamente
3. Caso necessÃ¡rio:
```bash 
docker compose restart
```

### ğŸ”¥ Reset Completo do Ambiente
Caso algo quebre:
```bash
docker compose down --volumes --remove-orphans
sudo rm -rf logs/*
sudo rm -rf config/*
docker compose up airflow-init
docker compose up -d
```

### ğŸ“Œ ObservaÃ§Ãµes Importantes
- A pasta logs/ cresce rapidamente.
- Nunca commitar logs no Git.
- Verifique permissÃµes caso ocorram erros de escrita.
- Certifique-se que a porta 8080 nÃ£o esteja sendo usada.

### ğŸ§  Arquitetura Simplificada

```mathematica
Docker Compose
    â†“
Postgres (metadata)
    â†“
Airflow Scheduler
    â†“
Airflow Webserver
    â†“
DAG CI/CD
    â†“
Deploy Modelo
```